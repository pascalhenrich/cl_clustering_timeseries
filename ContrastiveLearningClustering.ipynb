{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.fft import fft\n",
    "from pytorch_metric_learning import losses\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation Functions\n",
    "def temporal_augmentation(x, alpha=0.4, beta=0.5):\n",
    "    # random = torch.randint(0,1,(1,))\n",
    "    # if random == 0:\n",
    "    jitter = torch.normal(mean=0.0, std=alpha, size=x.shape)\n",
    "    return x + jitter\n",
    "    # else:\n",
    "    #     scale = torch.empty(1).uniform_(1-beta,1+beta).item()\n",
    "    #     return x * scale\n",
    "\n",
    "\n",
    "def frequency_augmentation(x):\n",
    "    # Example: Mask random frequency components\n",
    "    mask = torch.rand(x.size()).to(x.device)\n",
    "    mask[mask < 0.1] = 0  # Randomly zero out half of the components\n",
    "    return x * mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TemporalEncoder, self).__init__()\n",
    "        self.bilstm = nn.LSTM(1, 2, batch_first=True, bidirectional=True)\n",
    "        # self.layer = nn.Linear(2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        seq_len = x.size(1)\n",
    "        x, _ = self.bilstm(x.view(batch_size, seq_len,1))\n",
    "        # x = self.layer(x).view(batch_size, seq_len)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrequencyEncoder(nn.Module):\n",
    "    def __init__(self, batch_size, seq_len):\n",
    "        super(FrequencyEncoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.seq_len = seq_len\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=8, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=8, out_channels=16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, stride=2, padding=1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(8)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(16)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(32)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=3,stride=2)\n",
    "        self.dropout = nn.Dropout()\n",
    "        self.layer1 = nn.Linear(32*13, self.seq_len)\n",
    "        self.layer2 = nn.Linear(self.seq_len, self.seq_len)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.real\n",
    "        x = x.view(self.batch_size,1,-1)\n",
    "        x = self.pool(F.relu(self.batchnorm1(self.conv1(x))))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool(F.relu(self.batchnorm2(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.batchnorm3(self.conv3(x))))\n",
    "        x = self.layer1(x.view(self.batch_size,32*13))\n",
    "        x = self.layer2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstanceLevelTransformation(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(InstanceLevelTransformation, self).__init__()\n",
    "        self.layer1 = nn.Linear(1000*4, 1000*2)\n",
    "        self.layer2 = nn.Linear(1000*2, 1000)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = F.normalize(x, p=2, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClusterLevelTransformation(nn.Module):\n",
    "    def __init__(self, input_size,cluster_size):\n",
    "        super(ClusterLevelTransformation, self).__init__()\n",
    "        self.layer1 = nn.Linear(1000*4, 1000*2)\n",
    "        self.layer2 = nn.Linear(1000*2, 1000)\n",
    "        self.layer3 = nn.Linear(1000, cluster_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Definition\n",
    "class CDCCModel(nn.Module):\n",
    "    def __init__(self, seq_len=17520, feature_length=1752, cluster_size=10):\n",
    "        super(CDCCModel, self).__init__()\n",
    "        self.temporal_encoder = TemporalEncoder()\n",
    "        self.temporal_transform = InstanceLevelTransformation(seq_len,feature_length)\n",
    "        self.cluster_transform = ClusterLevelTransformation(seq_len,cluster_size)\n",
    "\n",
    "    def forward(self, x, train=True):\n",
    "        if train:\n",
    "            x_t, x_t_aug = x           \n",
    "\n",
    "            # Encodings\n",
    "            h_t = self.temporal_encoder(x_t)\n",
    "            h_t_aug = self.temporal_encoder(x_t_aug)\n",
    "\n",
    "            # Transformations\n",
    "            z_i = self.temporal_transform(h_t)\n",
    "            z_i_aug = self.temporal_transform(h_t_aug)\n",
    "            z_c = self.cluster_transform(h_t)\n",
    "            z_c_aug = self.cluster_transform(h_t_aug)\n",
    "            \n",
    "            return z_i,z_i_aug,z_c,z_c_aug\n",
    "        else:\n",
    "            return torch.argmax(self.cluster_transform(self.temporal_encoder(x)),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"Final_Energy_dataset.csv\")\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data = data[data['Date'].dt.date != pd.to_datetime('2012-02-29').date()]    \n",
    "prosumption = {}\n",
    "for i in range(101,301):\n",
    "    if (data[f'load_{i}'].isna().sum() == 0) & (data[f'pv_{i}'].isna().sum() == 0):\n",
    "        prosumption[f'prosumption_{i}'] = data[f'load_{i}'] - data[f'pv_{i}']\n",
    "data_train_df = pd.DataFrame(prosumption).reset_index(drop=True)\n",
    "data_train_df.to_csv('data_train.csv')\n",
    "\n",
    "# # data_train_tensor = torch.Tensor(data_train_df.values).reshape(600,17520)\n",
    "# data = data[((data['Date'].dt.month >= 7) & (data['Date'].dt.year == 2010)) \n",
    "#             | (((data['Date'].dt.month < 7) & (data['Date'].dt.year == 2011))) \n",
    "#             | (data['Date'] == pd.to_datetime('2011-07-01 00:00:00'))]\n",
    "# prosumption = {}\n",
    "# for i in range(1,101):\n",
    "#     if (data[f'load_{i}'].isna().sum() == 0) & (data[f'pv_{i}'].isna().sum() == 0):\n",
    "#         prosumption[f'prosumption_{i}'] = data[f'load_{i}'] - data[f'pv_{i}']\n",
    "# data_test_df = pd.DataFrame(prosumption).reset_index(drop=True).T\n",
    "# # data_test_df.to_csv('data_test.csv')\n",
    "# data_test_df\n",
    "# data_test_tensor = torch.Tensor(data_test_df.values).reshape(100,17520)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(tensor, batch_size):\n",
    "    indices = np.random.choice(tensor.shape[0], batch_size, replace=False)\n",
    "    return tensor[indices,0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InfocNCELoss(nn.Module):\n",
    "    def __init__(self, temperature=0.07):\n",
    "        super(InfocNCELoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, original, augmented):\n",
    "        # Batch size\n",
    "        batch_size = original.size(0)\n",
    "\n",
    "        # Normalize original and augmented embeddings\n",
    "        original = F.normalize(original, p=2, dim=1)   # (batch_size, embedding_dim)\n",
    "        augmented = F.normalize(augmented, p=2, dim=1)  # (batch_size, embedding_dim)\n",
    "\n",
    "        # Concatenate original and augmented embeddings (2 * batch_size, embedding_dim)\n",
    "        embeddings = torch.cat([original, augmented], dim=0)\n",
    "\n",
    "        # Compute similarity matrix (2 * batch_size, 2 * batch_size)\n",
    "        similarity_matrix = torch.mm(embeddings, embeddings.T)\n",
    "\n",
    "        # Create labels: For each anchor in the batch, the positive pair is the corresponding augmented one\n",
    "        labels = torch.cat([torch.arange(batch_size) + batch_size, torch.arange(batch_size)])\n",
    "\n",
    "        # Mask out self-similarity to avoid considering the same sample as both positive and negative\n",
    "        mask = torch.eye(2 * batch_size, dtype=torch.bool).to(original.device)\n",
    "        similarity_matrix.masked_fill_(mask, -float('inf'))\n",
    "\n",
    "        # Scale similarity matrix by temperature\n",
    "        similarity_matrix /= self.temperature\n",
    "\n",
    "        # Compute the InfoNCE loss\n",
    "        loss = F.cross_entropy(similarity_matrix, labels, reduction='mean')\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 50, Loss: 2.200089931488037\n",
      "Epoch 2 / 50, Loss: 3.3343005180358887\n",
      "Epoch 3 / 50, Loss: 3.1278891563415527\n",
      "Epoch 4 / 50, Loss: 2.98081374168396\n",
      "Epoch 5 / 50, Loss: 2.863985776901245\n",
      "Epoch 6 / 50, Loss: 2.6335625648498535\n",
      "Epoch 7 / 50, Loss: 2.3727290630340576\n",
      "Epoch 8 / 50, Loss: 2.2593278884887695\n",
      "Epoch 9 / 50, Loss: 1.8169331550598145\n",
      "Epoch 10 / 50, Loss: 1.919558048248291\n",
      "Epoch 11 / 50, Loss: 1.8670063018798828\n",
      "Epoch 12 / 50, Loss: 2.0564041137695312\n",
      "Epoch 13 / 50, Loss: 1.8606932163238525\n",
      "Epoch 14 / 50, Loss: 1.699446201324463\n",
      "Epoch 15 / 50, Loss: 1.3470531702041626\n",
      "Epoch 16 / 50, Loss: 1.5484182834625244\n",
      "Epoch 17 / 50, Loss: 1.7068978548049927\n",
      "Epoch 18 / 50, Loss: 1.4273288249969482\n",
      "Epoch 19 / 50, Loss: 1.3647443056106567\n",
      "Epoch 20 / 50, Loss: 1.6298375129699707\n",
      "Epoch 21 / 50, Loss: 1.57668936252594\n",
      "Epoch 22 / 50, Loss: 1.3508992195129395\n",
      "Epoch 23 / 50, Loss: 1.1075174808502197\n",
      "Epoch 24 / 50, Loss: 1.230635404586792\n",
      "Epoch 25 / 50, Loss: 0.8164557814598083\n",
      "Epoch 26 / 50, Loss: 0.7380474805831909\n",
      "Epoch 27 / 50, Loss: 1.0808706283569336\n",
      "Epoch 28 / 50, Loss: 1.1985409259796143\n",
      "Epoch 29 / 50, Loss: 0.7967724800109863\n",
      "Epoch 30 / 50, Loss: 0.9366906881332397\n",
      "Epoch 31 / 50, Loss: 1.2052768468856812\n",
      "Epoch 32 / 50, Loss: 0.6475095748901367\n",
      "Epoch 33 / 50, Loss: 0.8968873023986816\n",
      "Epoch 34 / 50, Loss: 0.7329436540603638\n",
      "Epoch 35 / 50, Loss: 0.9963505268096924\n",
      "Epoch 36 / 50, Loss: 1.2310961484909058\n",
      "Epoch 37 / 50, Loss: 0.9843081831932068\n",
      "Epoch 38 / 50, Loss: 0.8461153507232666\n",
      "Epoch 39 / 50, Loss: 0.7859874367713928\n",
      "Epoch 40 / 50, Loss: 1.1159477233886719\n",
      "Epoch 41 / 50, Loss: 1.1020045280456543\n",
      "Epoch 42 / 50, Loss: 0.9302446842193604\n",
      "Epoch 43 / 50, Loss: 0.7943671941757202\n",
      "Epoch 44 / 50, Loss: 0.6550210118293762\n",
      "Epoch 45 / 50, Loss: 0.9949524402618408\n",
      "Epoch 46 / 50, Loss: 1.2570852041244507\n",
      "Epoch 47 / 50, Loss: 1.0203195810317993\n",
      "Epoch 48 / 50, Loss: 0.7188639640808105\n",
      "Epoch 49 / 50, Loss: 0.8301184177398682\n",
      "Epoch 50 / 50, Loss: 0.7046641111373901\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "cluster_size = 10\n",
    "epochs = 50\n",
    "\n",
    "model = CDCCModel(cluster_size=cluster_size)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# loss_func = losses.SelfSupervisedLoss(losses.NTXentLoss(),symmetric=True)\n",
    "# cross_entropy_loss = torch.nn.CrossEntropyLoss()\n",
    "loss_func = InfocNCELoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    data = get_batch(data_train_tensor, batch_size)\n",
    "    data_aug = temporal_augmentation(data)\n",
    "\n",
    "    model.zero_grad()\n",
    "    # print(model(data_test_tensor[0:10],train=False))\n",
    "\n",
    "    \n",
    "    \n",
    "   \n",
    "    \n",
    "    a,b,c,d = model((data,data_aug))\n",
    "    \n",
    "    loss_i = (loss_func(a,b)+loss_func(b,a))/2\n",
    "    # loss_c = (loss_func(c.T,d.T)+loss_func(d.T,c.T))/2\n",
    "\n",
    "    # p_c = torch.mean(c, dim=0)\n",
    "    # p_c_aug = torch.mean(d, dim=0)\n",
    "    # p_c_clamp = torch.clamp(p_c, 1e-16, 1-1e-16)\n",
    "    # p_c_aug_clamp = torch.clamp(p_c_aug, 1e-16, 1-1e-16)\n",
    "    # loss_ce = -torch.sum(p_c*torch.log(p_c_clamp)-p_c_aug*torch.log(p_c_aug_clamp))\n",
    "    # print(loss_i,loss_c,loss_ce)\n",
    "    loss = loss_i #+ loss_c + loss_ce\n",
    "    print(f'Epoch {epoch+1} / {epochs}, Loss: {loss.item()}')\n",
    "\n",
    "\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 1, 8, 6, 1, 1, 1, 6, 6, 3, 6, 1, 6, 3, 3, 6, 1, 1, 1, 3, 6, 3, 1, 1,\n",
       "        1, 8, 1, 6, 1, 1, 6, 1, 8, 6, 8, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 6, 1, 6,\n",
       "        1, 1, 8, 6, 6, 6, 1, 8, 6, 6, 8, 6, 1, 6, 1, 1, 1, 6, 3, 8, 3, 6, 6, 6,\n",
       "        1, 6, 6, 6, 3, 8, 1, 1, 3, 6, 1, 1, 6, 6, 3, 1, 1, 1, 1, 8, 1, 6, 3, 1,\n",
       "        1, 8, 1, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(data_test_tensor[0:100,0:1000],train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor([[4., 5.]]) tensor([[10., 11.]])\n",
      "1\n",
      "tensor([[2., 3.]]) tensor([[8., 9.]])\n",
      "2\n",
      "tensor([[0., 1.]]) tensor([[6., 7.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from CDCC.data import CustomDataset \n",
    "\n",
    "\n",
    "cds = CustomDataset(torch.Tensor([[0,1],[2,3],[4,5]]), torch.Tensor([[6,7],[8,9],[10,11]]))\n",
    "train_loader = torch.utils.data.DataLoader(dataset=cds, batch_size=1, shuffle=True)\n",
    "for step, (x,y) in enumerate(train_loader):\n",
    "    print(step)\n",
    "    print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(X):\n",
    "    X = [int(x) for x in X]\n",
    "    n_values = np.max(X) + 1\n",
    "    b = np.eye(n_values)[X]\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = np.random.randint(0, 3, size=[10])\n",
    "li_onehot = one_hot_encoding(li)\n",
    "\n",
    "\n",
    "aug_1 = torch.randn((10,1,5))\n",
    "aug_2 = torch.randn((10,1,5))\n",
    "aug_3 = torch.randn((10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5793, -1.2249,  0.0726, -0.5853, -1.6182]],\n",
       "\n",
       "        [[ 0.3280,  1.2782, -0.6666,  1.2716,  0.0961]],\n",
       "\n",
       "        [[ 1.0612,  0.2259,  0.7334, -0.0340, -1.4629]],\n",
       "\n",
       "        [[ 0.2259,  0.3952,  0.7407, -0.6767, -0.1268]],\n",
       "\n",
       "        [[-0.2369, -0.1663, -0.6886,  0.6644, -0.2680]],\n",
       "\n",
       "        [[ 0.9437, -0.9627, -1.3485, -1.6521,  0.1040]],\n",
       "\n",
       "        [[ 0.1203,  2.4441,  0.3534,  2.6402, -2.1426]],\n",
       "\n",
       "        [[ 1.4571,  0.5752, -1.3446,  0.8272, -0.2093]],\n",
       "\n",
       "        [[ 0.5552, -1.6741,  1.4697, -0.7520,  1.0526]],\n",
       "\n",
       "        [[ 1.3351,  0.3985,  1.6254, -0.5584, -0.0519]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0., 0., 1., 1.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li_onehot[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 1.0612,  0.2259,  0.7334, -0.0340, -1.4629]],\n",
       "\n",
       "        [[ 0.2259,  0.3952,  0.7407, -0.6767, -0.1268]],\n",
       "\n",
       "        [[-0.2369, -0.1663, -0.6886,  0.6644, -0.2680]],\n",
       "\n",
       "        [[ 0.9437, -0.9627, -1.3485, -1.6521,  0.1040]],\n",
       "\n",
       "        [[ 0.1203,  2.4441,  0.3534,  2.6402, -2.1426]],\n",
       "\n",
       "        [[ 1.4571,  0.5752, -1.3446,  0.8272, -0.2093]],\n",
       "\n",
       "        [[ 0.5552, -1.6741,  1.4697, -0.7520,  1.0526]],\n",
       "\n",
       "        [[ 1.3351,  0.3985,  1.6254, -0.5584, -0.0519]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_1[1-li_onehot[:, 0]] = 0\n",
    "aug_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 1.6630, -0.1142,  1.4622, -1.5548, -3.4478]],\n",
       "\n",
       "        [[ 0.1657,  1.3081, -0.5880,  0.0646,  0.0420]],\n",
       "\n",
       "        [[-1.1388,  0.0850, -2.1036, -0.2397,  1.6391]],\n",
       "\n",
       "        [[-0.4124, -2.2816, -1.6095, -0.5997, -0.2591]],\n",
       "\n",
       "        [[-0.0450,  2.0129,  1.7478,  2.6780, -0.9558]],\n",
       "\n",
       "        [[ 1.9480,  0.6407, -0.8891,  2.4291, -0.1961]],\n",
       "\n",
       "        [[-0.4355, -2.4739,  1.8967, -1.6155, -0.1899]],\n",
       "\n",
       "        [[ 1.2263, -0.0360,  1.3802, -0.6694,  1.5923]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_2[1 - li_onehot[:, 1]] = 0\n",
    "aug_2 + aug_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.2232, -0.2033,  0.2780,  1.5442, -0.2986],\n",
       "        [ 0.5432, -0.8082,  0.8530,  0.5093,  0.9201],\n",
       "        [ 0.6298,  0.3081, -0.4960, -0.6870,  1.2107],\n",
       "        [ 1.3851, -0.0438,  0.9864,  1.5693, -0.0670],\n",
       "        [-2.5290,  0.3443,  0.8076,  2.0789, -1.1172],\n",
       "        [-0.6643, -0.4576, -2.0311,  0.4557, -1.2855],\n",
       "        [-0.1285,  0.1837,  0.3927,  0.3390, -0.0385],\n",
       "        [-0.5163, -2.0811,  1.6169,  0.2710,  1.4350]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_3[1 - li_onehot[:, 2]] = 0\n",
    "aug_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.3416, -0.8452, -0.6422,  0.0633, -0.4780]],\n",
      "\n",
      "        [[-0.9844,  0.5087,  0.0307, -1.6512,  0.4128]],\n",
      "\n",
      "        [[-0.4520,  1.7438, -0.3762,  1.2024,  0.7313]],\n",
      "\n",
      "        [[ 1.5930, -1.3147, -1.8538,  0.6295,  0.9402]],\n",
      "\n",
      "        [[ 0.8831, -1.5312, -0.9452, -0.5693,  1.9478]],\n",
      "\n",
      "        [[-0.1362,  0.3734, -1.1859,  0.4234, -0.5096]],\n",
      "\n",
      "        [[-0.6835,  0.2497, -0.0903,  0.2238, -0.9135]],\n",
      "\n",
      "        [[-0.4787,  2.3719,  2.6252,  0.9116, -0.3260]],\n",
      "\n",
      "        [[ 0.4229, -0.8545, -0.9561,  1.2805, -0.4317]],\n",
      "\n",
      "        [[ 0.4608,  0.2143,  0.8601,  1.2083,  0.3726]]])\n"
     ]
    }
   ],
   "source": [
    "from CDCC.augmentations import DataTransform_T\n",
    "import torch\n",
    "\n",
    "data = torch.randn((10,1,5))\n",
    "print(data)\n",
    "og, aug, aug_1, aug_2 = DataTransform_T(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.8460,  0.3896, -1.9531,  0.6685, -0.4961]],\n",
       "\n",
       "        [[-0.4794,  1.8077,  0.5057, -1.7047,  0.3446]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.9263,  0.0098, -1.0915, -1.0077,  2.1601]],\n",
       "\n",
       "        [[-0.2912,  0.1276, -1.2833, -0.6458, -0.3417]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-1.0142,  2.4772,  2.5777,  0.9885, -1.2949]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.0462,  2.3482,  1.1745,  1.7759,  0.8536]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.3368,  4.5153, -0.8592,  4.0130,  0.9832]],\n",
       "\n",
       "        [[-0.0084, -2.3238,  0.3291,  2.2169,  1.3606]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-2.6010,  0.5544, -0.2498,  0.2932, -0.1370]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.6564, -1.1039, -0.0147,  3.1929, -1.0673]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.8460,  0.3896, -1.9531,  0.6685, -0.4961]],\n",
       "\n",
       "        [[-0.4794,  1.8077,  0.5057, -1.7047,  0.3446]],\n",
       "\n",
       "        [[-0.3368,  4.5153, -0.8592,  4.0130,  0.9832]],\n",
       "\n",
       "        [[-0.0084, -2.3238,  0.3291,  2.2169,  1.3606]],\n",
       "\n",
       "        [[ 0.9263,  0.0098, -1.0915, -1.0077,  2.1601]],\n",
       "\n",
       "        [[-0.2912,  0.1276, -1.2833, -0.6458, -0.3417]],\n",
       "\n",
       "        [[-2.6010,  0.5544, -0.2498,  0.2932, -0.1370]],\n",
       "\n",
       "        [[-1.0142,  2.4772,  2.5777,  0.9885, -1.2949]],\n",
       "\n",
       "        [[ 0.6564, -1.1039, -0.0147,  3.1929, -1.0673]],\n",
       "\n",
       "        [[ 0.0462,  2.3482,  1.1745,  1.7759,  0.8536]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.02176858,  0.01144502, -0.08667886,  0.00933849,\n",
       "         -0.05837898]],\n",
       "\n",
       "       [[ 0.12338087, -0.06858338, -0.0408963 ,  0.08756479,\n",
       "         -0.02262905]],\n",
       "\n",
       "       [[-0.04923796, -0.06444042,  0.06061122,  0.04512797,\n",
       "         -0.06934294]],\n",
       "\n",
       "       [[-0.06387301, -0.08351301, -0.0648921 , -0.10544478,\n",
       "         -0.06138439]],\n",
       "\n",
       "       [[-0.09932564,  0.01588636, -0.06083638,  0.09049226,\n",
       "          0.06108832]],\n",
       "\n",
       "       [[ 0.11520715, -0.06738591,  0.14733264, -0.09010899,\n",
       "          0.05196283]],\n",
       "\n",
       "       [[ 0.00752993, -0.11395712,  0.15157864,  0.22666766,\n",
       "          0.0009768 ]],\n",
       "\n",
       "       [[-0.10626585, -0.17359035, -0.01501222, -0.11532472,\n",
       "         -0.1030506 ]],\n",
       "\n",
       "       [[ 0.00765463, -0.00215181,  0.1716162 , -0.24035026,\n",
       "          0.06983744]],\n",
       "\n",
       "       [[ 0.07757059, -0.03414363,  0.02834073, -0.02988733,\n",
       "         -0.15754228]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.normal(loc=0., scale=0.1, size=(10,1,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1218,  0.0164, -0.8406,  0.4303, -0.8673]],\n",
       "\n",
       "        [[-1.6456,  1.3475, -0.6096,  1.1897, -0.9227]],\n",
       "\n",
       "        [[ 0.4306, -1.4497,  0.7396,  0.4622,  0.0610]],\n",
       "\n",
       "        [[ 0.7240, -0.4813,  0.1264, -0.4526,  1.6689]],\n",
       "\n",
       "        [[ 0.0981,  0.7305,  1.1890,  0.1520, -0.8134]],\n",
       "\n",
       "        [[-0.8173,  0.0363, -0.6241, -1.4054,  1.5949]],\n",
       "\n",
       "        [[ 0.5530, -0.4701,  0.2775,  0.5016, -1.0726]],\n",
       "\n",
       "        [[-0.9671,  0.9827, -0.8305,  0.2212,  1.0194]],\n",
       "\n",
       "        [[-0.4848,  0.6745,  0.8543, -0.8525,  0.7640]],\n",
       "\n",
       "        [[-1.3935,  0.1515,  0.7019, -1.1955, -0.4908]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "x = torch.randn((10,1,5))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(x[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
